{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5412f57",
      "metadata": {
        "id": "f5412f57"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85d0f315"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn import tree"
      ],
      "id": "85d0f315"
    },
    {
      "cell_type": "markdown",
      "id": "0e71121b",
      "metadata": {
        "id": "0e71121b"
      },
      "source": [
        "# Intro\n",
        "\n",
        "The first part of this notebook uses a toy dataset to illustrate __how splits are made and evaluated__ when constructing a classification tree.\n",
        "\n",
        "The example ilustrates splits done on a quantitative predictor (Income).\n",
        "\n",
        "The example evaluates the splits based on the error rate. Notice that the CART algorithm implemented in scikit learn does not use the error rate to make splits. It uses either the Gini index or Entropy (whichever the user chooses)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c6a6e7",
      "metadata": {
        "id": "01c6a6e7"
      },
      "source": [
        "__Creating the toy dataset__\n",
        "\n",
        "There are three predictors. The outcome variable is Credit_Risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbc87bf",
      "metadata": {
        "id": "3fbc87bf"
      },
      "outputs": [],
      "source": [
        "toy_df_classif = pd.DataFrame({'Savings':['Med','Low','High','Med','Low','High','Low','Med'], 'Assets':['High','Low','Med','Med','Med','High','Low','Med'], 'Income':[75,50,25,50,100,25,25,75], 'Credit_Risk':['Good','Bad','Bad','Good','Good','Good','Bad','Good']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c2a63a9",
      "metadata": {
        "id": "2c2a63a9"
      },
      "outputs": [],
      "source": [
        "toy_df_classif"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d22682",
      "metadata": {
        "id": "00d22682"
      },
      "source": [
        "#### Exploring how splits are made when constructing a CT\n",
        "#### Exploring splits on Income\n",
        "\n",
        "The first thing to do before creating __the possible splits__ on a quantitative predictor is to __obtain the cutoff points__.\n",
        "\n",
        "To obtain the possible cutoff points, I will first store all Income values (excluding duplicates) in an array called __Income_unique__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2c716a",
      "metadata": {
        "id": "8b2c716a"
      },
      "outputs": [],
      "source": [
        "Income_unique= np.sort(toy_df_classif['Income'].unique())\n",
        "Income_unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a0aef3",
      "metadata": {
        "id": "b7a0aef3"
      },
      "outputs": [],
      "source": [
        "cutpoints=[]\n",
        "for i in np.arange(len(Income_unique)-1):  # I need i to reach only the second to last index (not  last one). np.arange(len(x)-1) generates the numbers 0,1,2\n",
        "    cutpoints.append((Income_unique[i]+ Income_unique[i+1])/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e979c7",
      "metadata": {
        "id": "a1e979c7"
      },
      "outputs": [],
      "source": [
        "cutpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39829d7b",
      "metadata": {
        "id": "39829d7b"
      },
      "source": [
        "The algorithm will find an split using Income based on these three cutpoints and would decide the best split (i.e., the split\n",
        "leading to the purest child nodes).\n",
        "\n",
        "The next code cells will show in details (step by step) how __to obtain and evaluate ONLY the split done at 37.5.__ Later on, you will see a loop where all three cutoff points are evaluated."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Reminder__: The algorithm would also do all the possible splits for the other two predictors, Savings and Assets, and would actually choose the best split obtained across all three predictors and across all cutoffs tested for each predictor."
      ],
      "metadata": {
        "id": "s9d_9YR0S4YE"
      },
      "id": "s9d_9YR0S4YE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e7663fb",
      "metadata": {
        "id": "1e7663fb"
      },
      "outputs": [],
      "source": [
        "# LEFT NODE FOR CUTPOINT 37.5\n",
        "\n",
        "toy_df_classif.loc[toy_df_classif['Income'] <= 37.5, ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851687bc",
      "metadata": {
        "id": "851687bc"
      },
      "outputs": [],
      "source": [
        "# RIGHT NODE FOR CUTPOINT 37.5\n",
        "\n",
        "toy_df_classif.loc[toy_df_classif['Income']> 37.5, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17328b91",
      "metadata": {
        "id": "17328b91"
      },
      "source": [
        "__What's the prediction of Y for the left node?__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cab9e03",
      "metadata": {
        "id": "4cab9e03"
      },
      "source": [
        "Answer: The prediction is Bad because it is the most common class in this node. The next two code cells show you how to get this label programmatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03b0390",
      "metadata": {
        "id": "a03b0390"
      },
      "outputs": [],
      "source": [
        "toy_df_classif.loc[toy_df_classif['Income'] <= 37.5, ]['Credit_Risk'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f5f47d",
      "metadata": {
        "id": "39f5f47d"
      },
      "outputs": [],
      "source": [
        "toy_df_classif.loc[toy_df_classif['Income'] <= 37.5, ]['Credit_Risk'].value_counts().idxmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2e58a7",
      "metadata": {
        "id": "ce2e58a7"
      },
      "source": [
        "__What's the error rate at the left node?__\n",
        "\n",
        "Error rate for left node = 1/3 (proportion for the least frequent class in this node, which is Good)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With code\n",
        "\n",
        "error_left = toy_df_classif.loc[toy_df_classif['Income'] <= 37.5, ]['Credit_Risk'].value_counts(normalize=True).min()"
      ],
      "metadata": {
        "id": "MAfDrHwUffU7"
      },
      "id": "MAfDrHwUffU7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_left"
      ],
      "metadata": {
        "id": "LM_-NcUtwo2C"
      },
      "id": "LM_-NcUtwo2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ce06a7e9",
      "metadata": {
        "id": "ce06a7e9"
      },
      "source": [
        "__What's the prediction of Y for the right node?__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: The prediction is Good because it is the most common class in this node."
      ],
      "metadata": {
        "id": "p4Pu3vCLvWq0"
      },
      "id": "p4Pu3vCLvWq0"
    },
    {
      "cell_type": "code",
      "source": [
        "toy_df_classif.loc[toy_df_classif['Income'] > 37.5, ]['Credit_Risk'].value_counts().idxmax()"
      ],
      "metadata": {
        "id": "lRx3InHDv8xs"
      },
      "id": "lRx3InHDv8xs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__What's the error rate at the right node?__\n",
        "\n",
        "\n",
        "Error rate for right node = 1/5= 0.2 (proportion of obs that belong to the least frequent class)"
      ],
      "metadata": {
        "id": "pOeMQouevZ9C"
      },
      "id": "pOeMQouevZ9C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9191e6b",
      "metadata": {
        "id": "c9191e6b"
      },
      "outputs": [],
      "source": [
        "# With code\n",
        "\n",
        "error_right= toy_df_classif.loc[toy_df_classif['Income'] > 37.5, ]['Credit_Risk'].value_counts(normalize=True).min()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_right"
      ],
      "metadata": {
        "id": "ebxQH2ipwv2B"
      },
      "id": "ebxQH2ipwv2B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d15fc5b3",
      "metadata": {
        "id": "d15fc5b3"
      },
      "source": [
        "__What's the error associated with making a split at 37.5 based on Income?__\n",
        "\n",
        "Combine the error rate from both the left and right node!\n",
        "\n",
        "How can we combine these errors? We need to obtain the weighted average of the errors for the left and right nodes.\n",
        "\n",
        "__Error for split at 37.5= weight for left node * error rate for left node + weight for right node * error rate for right node__\n",
        "\n",
        "weight for left node= obs that reached the left node/ obs before the split\n",
        "\n",
        "weight for right node= obs that reached the right node/ obs before the split\n",
        "\n",
        "__Curiosity:__ Notice that the unweighted average (which we do not need to compute), we will be obtained:\n",
        "\n",
        "Unweighted average = (error rate for left node + error rate for right node)/ 2 = 0.5 * error rate for left node + 0.5 * error rate for right node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97d35b9",
      "metadata": {
        "id": "a97d35b9"
      },
      "outputs": [],
      "source": [
        "left_node_size= len (toy_df_classif.loc[toy_df_classif['Income'] <= 37.5, ])\n",
        "left_node_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03566fa3",
      "metadata": {
        "id": "03566fa3"
      },
      "outputs": [],
      "source": [
        "right_node_size= len (toy_df_classif.loc[toy_df_classif['Income'] > 37.5, ] )\n",
        "right_node_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b306a6b1",
      "metadata": {
        "id": "b306a6b1"
      },
      "outputs": [],
      "source": [
        "# Weighted error for the split\n",
        "\n",
        "error_left * (left_node_size/(left_node_size+right_node_size)) + error_right * (right_node_size/(left_node_size+right_node_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the split benefitial? Is the error after the split lower than the error before split?"
      ],
      "metadata": {
        "id": "xLuB8vZYS71a"
      },
      "id": "xLuB8vZYS71a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d952e6",
      "metadata": {
        "id": "b4d952e6"
      },
      "outputs": [],
      "source": [
        "# Error before the split\n",
        "\n",
        "toy_df_classif['Credit_Risk'].value_counts(normalize= True).min()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3/8"
      ],
      "metadata": {
        "id": "J2UK3Z0HgPFq"
      },
      "id": "J2UK3Z0HgPFq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing an split at 37.5 is benefitial because the error rate after the split is lower than the error rate before the split."
      ],
      "metadata": {
        "id": "bFsL5K0xebCL"
      },
      "id": "bFsL5K0xebCL"
    },
    {
      "cell_type": "markdown",
      "id": "7a3c3c80",
      "metadata": {
        "id": "7a3c3c80"
      },
      "source": [
        "The previous code cells included the steps to compute the weighted error rate for the split at 37.5 on Income.\n",
        "\n",
        "The next loop summarizes the computation of the weighted error for the three splits on Income, that is the splits at 37.5, 62.5, and 87.5.\n",
        "\n",
        "We can get what's the best of all the splits for Income based on the output of this loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3b893c",
      "metadata": {
        "id": "1a3b893c"
      },
      "outputs": [],
      "source": [
        "error_rate_splits =[]\n",
        "for i in cutpoints:\n",
        "    left_node_size= len (toy_df_classif.loc[toy_df_classif['Income'] <= i, ])\n",
        "    right_node_size= len (toy_df_classif.loc[toy_df_classif['Income'] > i, ] )\n",
        "    error_left= toy_df_classif['Credit_Risk'][toy_df_classif['Income']<=i].value_counts(normalize=True).min()\n",
        "    error_right= toy_df_classif['Credit_Risk'][toy_df_classif['Income']>i].value_counts(normalize=True).min()\n",
        "    error_rate_splits.append(error_left*(left_node_size/(left_node_size+right_node_size)) + error_right*(right_node_size/(left_node_size+right_node_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e92de0",
      "metadata": {
        "scrolled": true,
        "id": "c8e92de0"
      },
      "outputs": [],
      "source": [
        "error_rate_splits_df= pd.DataFrame (data= error_rate_splits, index= cutpoints, columns=['Weighted_Error_Split'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0594d06",
      "metadata": {
        "id": "c0594d06"
      },
      "outputs": [],
      "source": [
        "error_rate_splits_df.index.name = ('Cutoff_point')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce7bfd0",
      "metadata": {
        "scrolled": false,
        "id": "cce7bfd0"
      },
      "outputs": [],
      "source": [
        "error_rate_splits_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0ed714",
      "metadata": {
        "id": "bc0ed714"
      },
      "source": [
        "The best split and only meaningful split is the one at 37.5 because it leads to the lowest error rate (and the only error rate lower than the error rate at the parent node)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1910f742",
      "metadata": {
        "id": "1910f742"
      },
      "source": [
        "### BACK TO THE SLIDES !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f70e4e",
      "metadata": {
        "id": "18f70e4e"
      },
      "source": [
        "### Example comparing error rate, Gini, and Entropy.\n",
        "\n",
        "### **YOU WILL EXPLORE THIS EXAMPLE INDEPENDENTLY !!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following example will show that the Gini index and Entropy are more sensitive to changes in the node probabilities than the error rate.\n",
        "\n",
        "- Y has two classes (0 and 1)\n",
        "- The node under consideration contains 800 obs, 400 from each class.\n",
        "- Split 1 leads to a left node with 300 zeros and 100 ones AND a right node with  100 zeros and 300 ones.\n",
        "- Split 2 leads to a left node with 200 zeros and 400 ones AND a right node with  200 zeros and 0 ones.\n",
        "- Compute the error rate, Gini, and Entropy for both splits."
      ],
      "metadata": {
        "id": "Ej3otgFszMSM"
      },
      "id": "Ej3otgFszMSM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error rate split 1\n",
        "\n",
        "Reminder: Error rate for a split=  Average weighted error\n",
        "\n",
        "Average weighted error= Weight for left node * error rate for left node + weight for right node * error rate for right node"
      ],
      "metadata": {
        "id": "W6m-wOH7Yumc"
      },
      "id": "W6m-wOH7Yumc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a26180",
      "metadata": {
        "id": "66a26180"
      },
      "outputs": [],
      "source": [
        "(400/800)* (100/400) + (400/800)* (100/400)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error rate split 2"
      ],
      "metadata": {
        "id": "3lo2M6ncY08-"
      },
      "id": "3lo2M6ncY08-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2316bd",
      "metadata": {
        "id": "bd2316bd"
      },
      "outputs": [],
      "source": [
        "(600/800)* (200/600) + (200/800)* (0/200) # the right node for split 2 is completely pure!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a9ecf4",
      "metadata": {
        "id": "a9a9ecf4"
      },
      "source": [
        "According to the error rate, splits 1 and 2 are equally good."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini split 1\n",
        "\n",
        "Gini index for a split= Weighted Gini for the split\n",
        "\n",
        "Weighted Gini for the split= Weight for left node * Gini for left node + weight for right node * Gini for right node\n",
        "\n",
        "G= 2 p1 (1-p1)"
      ],
      "metadata": {
        "id": "QwfHQHXTZDm7"
      },
      "id": "QwfHQHXTZDm7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af4d153d",
      "metadata": {
        "id": "af4d153d"
      },
      "outputs": [],
      "source": [
        "(400/800)* (2*(100/400)*(300/400)) + (400/800)* (2*(300/400)*(100/400))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 - (100/400) = 300/400"
      ],
      "metadata": {
        "id": "zMMTglSumk91"
      },
      "id": "zMMTglSumk91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini split 2"
      ],
      "metadata": {
        "id": "EGxm6MmeZZkq"
      },
      "id": "EGxm6MmeZZkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef561a9f",
      "metadata": {
        "id": "ef561a9f"
      },
      "outputs": [],
      "source": [
        "(600/800)* (2*(400/600)*(200/600)) + (200/800)* (2*(0/200)*(200/200))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cddea4a",
      "metadata": {
        "id": "3cddea4a"
      },
      "source": [
        "According to Gini, split 2 is better. Gini heavily weighs the fact that split 2 gives us a perfectly pure node."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy split 1\n",
        "\n",
        "Entropy for a split= Weighted Entropy for the split\n",
        "\n",
        "Weighted Entropy for the split= Weight for left node * Entropy for left node + weight for right node * Entropy for right node\n",
        "\n",
        "D= - (1-p1) * log (1 -p1) - p1 * log(p1)\n",
        "\n",
        "Reminder: p1 for the left node in split 1 is 100/400\n",
        "\n",
        "Reminder: p1 for the right node in split 1 is 300/400"
      ],
      "metadata": {
        "id": "V9P6nKnDZq1Y"
      },
      "id": "V9P6nKnDZq1Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2060e2ac",
      "metadata": {
        "id": "2060e2ac"
      },
      "outputs": [],
      "source": [
        "(400/800)* (-(300/400)*np.log(300/400)- (100/400)*np.log(100/400)) + \\\n",
        "(400/800)* (-(100/400)*np.log(100/400) -(300/400)*np.log(300/400))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy split 2\n",
        "\n",
        "D= - (1-p1) * log (1 -p1) - p1 * log(p1)\n",
        "\n",
        "Reminder: p1 for the left node in split 2 is 400/600\n",
        "\n",
        "Reminder: p1 for the right node in split 2 is 0"
      ],
      "metadata": {
        "id": "I8E107pwZzhd"
      },
      "id": "I8E107pwZzhd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5408c72e",
      "metadata": {
        "id": "5408c72e"
      },
      "outputs": [],
      "source": [
        "(600/800)* ( -(200/600)*np.log(200/600) - (400/600)*np.log(400/600) ) + \\\n",
        "(200/800)* (- (1-0) * np.log (1 -0) - 0 * 0)\n",
        "\n",
        "# Note: We are assuming that log (0) = 0. In reality, log (0) is not defined."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb05c4d",
      "metadata": {
        "id": "1fb05c4d"
      },
      "source": [
        "According to the Entropy, split 2 is better. Similarly to Gini, Entropy heavily weighs the fact that split 2 gives us a perfectly pure node"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ef5888",
      "metadata": {
        "id": "60ef5888"
      },
      "source": [
        "## Example 1: Obtaining a classification tree for the Default data set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yY5XXMpxf6uR"
      },
      "id": "yY5XXMpxf6uR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_data_path = '/content/drive/MyDrive/CAP 4633C/Datasets_CAP4633C/Default.csv'"
      ],
      "metadata": {
        "id": "dKA-HOfzgEzN"
      },
      "id": "dKA-HOfzgEzN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9dd44a",
      "metadata": {
        "id": "7a9dd44a"
      },
      "outputs": [],
      "source": [
        "default_df = pd.read_csv(default_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54172317",
      "metadata": {
        "id": "54172317"
      },
      "outputs": [],
      "source": [
        "default_df_dummies = pd.get_dummies(default_df,columns=['student'], drop_first= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac35565",
      "metadata": {
        "id": "fac35565"
      },
      "outputs": [],
      "source": [
        "default_df_dummies.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_def = default_df_dummies.drop ('default', axis=1)"
      ],
      "metadata": {
        "id": "zHl4LUxUUunz"
      },
      "id": "zHl4LUxUUunz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_def = default_df_dummies['default']"
      ],
      "metadata": {
        "id": "GB_2qVC7Uv99"
      },
      "id": "GB_2qVC7Uv99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-pruning strategy using GridSearch."
      ],
      "metadata": {
        "id": "AEgm5teSghde"
      },
      "id": "AEgm5teSghde"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder: Pre-pruning means preventing the final tree to be too big by setting up several stopping criteria."
      ],
      "metadata": {
        "id": "v4SCpfwej89i"
      },
      "id": "v4SCpfwej89i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b8e08e",
      "metadata": {
        "id": "29b8e08e"
      },
      "outputs": [],
      "source": [
        "X_train_def, X_test_def, y_train_def, y_test_def = train_test_split (X_def, y_def, test_size= 0.2, random_state= 1, stratify = y_def)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb03b72a",
      "metadata": {
        "id": "bb03b72a"
      },
      "outputs": [],
      "source": [
        "# Notice that we have an extra hyperparameter here when compared to regression trees: 'criterion'.\n",
        "# Therefore, I am using fewer options for each hyperparameter in comparison with regression trees to minimize comp time.\n",
        "\n",
        "hyperparam_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': np.arange(2, 7), # depths from 2 to 6. It is rare that the best depth is > 5 anyways\n",
        "    'min_samples_split':[0.05, 0.1, 0.15, 0.2],\n",
        "    'min_samples_leaf':[0.05, 0.1, 0.15, 0.2],\n",
        "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.01, 0.05]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_set_up = KFold (n_splits= 10 , shuffle= True, random_state= 1)"
      ],
      "metadata": {
        "id": "V7ZbDzAgVP3N"
      },
      "id": "V7ZbDzAgVP3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f61cac3c",
      "metadata": {
        "id": "f61cac3c"
      },
      "outputs": [],
      "source": [
        "grid_search_setting_pre_pru = GridSearchCV(DecisionTreeClassifier(random_state= 1), hyperparam_grid, cv = cv_set_up, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11315812",
      "metadata": {
        "id": "11315812"
      },
      "outputs": [],
      "source": [
        "grid_search_setting_pre_pru.fit(X_train_def, y_train_def)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02dd19a",
      "metadata": {
        "id": "a02dd19a"
      },
      "outputs": [],
      "source": [
        "print('The best hyperparameters are: ', grid_search_setting_pre_pru.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b9ea11",
      "metadata": {
        "id": "06b9ea11"
      },
      "outputs": [],
      "source": [
        "tree_default_prepruned = DecisionTreeClassifier(criterion='gini', max_depth = 2, min_samples_split = 0.05, min_samples_leaf = 0.05, min_impurity_decrease = 0, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that you can also retrieve the best solution by simply invoking the 'best_estimator_' attribute on the grid search object. Like this:\n",
        "\n",
        "tree_default_prepruned = grid_search_setting_pre_pru.best_estimator_"
      ],
      "metadata": {
        "id": "j3jofAH21Eo1"
      },
      "id": "j3jofAH21Eo1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62fb75f",
      "metadata": {
        "id": "a62fb75f"
      },
      "outputs": [],
      "source": [
        "tree_default_prepruned.fit(X_train_def, y_train_def)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52d1712",
      "metadata": {
        "id": "f52d1712"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "tree.plot_tree(tree_default_prepruned, filled=True, rounded= True, feature_names=X_train_def.columns, fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_default_prepruned.classes_"
      ],
      "metadata": {
        "id": "RIvNGCtHasAe"
      },
      "id": "RIvNGCtHasAe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dec1e90",
      "metadata": {
        "id": "4dec1e90"
      },
      "outputs": [],
      "source": [
        "y_pred_pre_tree_def = tree_default_prepruned.predict(X_test_def)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fc31bb1",
      "metadata": {
        "id": "8fc31bb1"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test_def, y_pred_pre_tree_def)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without obtaining the classification report, tell me the specificity and sensitivity of this classifier."
      ],
      "metadata": {
        "id": "UssIqOllzdgn"
      },
      "id": "UssIqOllzdgn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Specificity = Recall for 0 class ('No' class)\n",
        "\n"
      ],
      "metadata": {
        "id": "lgqO-cPDzo1f"
      },
      "id": "lgqO-cPDzo1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sensitivity = Recall for 1 class ('Yes' class)\n",
        "\n"
      ],
      "metadata": {
        "id": "JRvRUY6nzuwz"
      },
      "id": "JRvRUY6nzuwz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ae3dd80",
      "metadata": {
        "id": "1ae3dd80"
      },
      "source": [
        "### Post-pruning via CCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a903e90",
      "metadata": {
        "id": "7a903e90"
      },
      "outputs": [],
      "source": [
        "# We are growing a big (unpruned) tree using Gini (which is the default criterion)\n",
        "\n",
        "tree_default_unpruned = DecisionTreeClassifier(criterion='gini', random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_default_unpruned.fit(X_train_def , y_train_def)"
      ],
      "metadata": {
        "id": "jT8AtXuOiTL7"
      },
      "id": "jT8AtXuOiTL7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccp_path= tree_default_unpruned.cost_complexity_pruning_path(X_train_def , y_train_def)"
      ],
      "metadata": {
        "id": "8uUKc0qPiTIu"
      },
      "id": "8uUKc0qPiTIu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_grid_alpha = { 'ccp_alpha': ccp_path.ccp_alphas}"
      ],
      "metadata": {
        "id": "gD6V46Z-X_X2"
      },
      "id": "gD6V46Z-X_X2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearch_alpha = GridSearchCV(tree_default_unpruned, hyperparam_grid_alpha,  cv= cv_set_up , scoring='accuracy', n_jobs= -1)"
      ],
      "metadata": {
        "id": "RNY1193fYGBp"
      },
      "id": "RNY1193fYGBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearch_alpha.fit(X_train_def, y_train_def)"
      ],
      "metadata": {
        "id": "9B1J_l_-iTAi"
      },
      "id": "9B1J_l_-iTAi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best parameters are: ', gridSearch_alpha.best_params_)"
      ],
      "metadata": {
        "id": "3Eh0QTlTYlap"
      },
      "id": "3Eh0QTlTYlap",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_default_postpruned= DecisionTreeClassifier( random_state=1, ccp_alpha= gridSearch_alpha.best_params_['ccp_alpha'])"
      ],
      "metadata": {
        "id": "bE6kqMRliS4p"
      },
      "id": "bE6kqMRliS4p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_default_postpruned.fit(X_train_def, y_train_def)"
      ],
      "metadata": {
        "id": "8sHCcc8QiSzm"
      },
      "id": "8sHCcc8QiSzm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "tree.plot_tree(tree_default_postpruned,filled=True, rounded= True, feature_names=X_train_def.columns, fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qCt7jcHcldsQ"
      },
      "id": "qCt7jcHcldsQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_post_pr_tree_def = tree_default_postpruned.predict(X_test_def)"
      ],
      "metadata": {
        "id": "RvTieb3MldpY"
      },
      "id": "RvTieb3MldpY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix (y_test_def, y_pred_post_pr_tree_def)"
      ],
      "metadata": {
        "id": "ok-GYt4Jldmw"
      },
      "id": "ok-GYt4Jldmw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (classification_report (y_test_def, y_pred_post_pr_tree_def))"
      ],
      "metadata": {
        "id": "guKvUdQDldjw"
      },
      "id": "guKvUdQDldjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__What are the most important predictors?__"
      ],
      "metadata": {
        "id": "A_MEJLLGdE-Q"
      },
      "id": "A_MEJLLGdE-Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What predictors show up in the tree?"
      ],
      "metadata": {
        "id": "EVGv1TbAdxwA"
      },
      "id": "EVGv1TbAdxwA"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_def.columns [tree_default_postpruned.feature_importances_!=0]"
      ],
      "metadata": {
        "id": "NcESEyXYdF5a"
      },
      "id": "NcESEyXYdF5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the importance of each predictor?"
      ],
      "metadata": {
        "id": "oHQ_McDmd5IV"
      },
      "id": "oHQ_McDmd5IV"
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({'Feature': X_train_def.columns, 'Importance': tree_default_postpruned.feature_importances_})"
      ],
      "metadata": {
        "id": "2zzIKqjghnDQ"
      },
      "id": "2zzIKqjghnDQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.sort_values(by='Importance', ascending=False)"
      ],
      "metadata": {
        "id": "1OzhAyQTh2U1"
      },
      "id": "1OzhAyQTh2U1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the ROC curve and AUC."
      ],
      "metadata": {
        "id": "K0qx6POXmkpm"
      },
      "id": "K0qx6POXmkpm"
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_postpruned = roc_auc_score(y_test_def, tree_default_postpruned.predict_proba(X_test_def)[:, 1])"
      ],
      "metadata": {
        "id": "qfXHzl4Elq9L"
      },
      "id": "qfXHzl4Elq9L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round (roc_auc_postpruned, 3)"
      ],
      "metadata": {
        "id": "EcEfClc8lq53"
      },
      "id": "EcEfClc8lq53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, threshold = roc_curve(y_test_def, tree_default_postpruned.predict_proba(X_test_def)[:, 1], pos_label='Yes')"
      ],
      "metadata": {
        "id": "-bDGUJpvZxdv"
      },
      "id": "-bDGUJpvZxdv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC ='+ str (np.round (roc_auc_postpruned, 3)))\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'k--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Qurw4tFZ9kH"
      },
      "id": "3Qurw4tFZ9kH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the performance of NB and the post-pruned tree based on AUC:\n",
        "\n",
        "NB results:\n",
        "\n",
        "AUC= 0.951\n",
        "\n",
        "\n",
        "The NB classifier gives a better balance between sensitivity and specificity across multiple probability thresholds (because it has a higher AUC)."
      ],
      "metadata": {
        "id": "tIuq6eWHh-nJ"
      },
      "id": "tIuq6eWHh-nJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Obtaining a classification tree for the Churning dataset"
      ],
      "metadata": {
        "id": "MHbJ9Pd4jpFW"
      },
      "id": "MHbJ9Pd4jpFW"
    },
    {
      "cell_type": "code",
      "source": [
        "churning_data_path= '/content/drive/MyDrive/CAP 4633C/Datasets_CAP4633C/bank_customer_churn.csv'"
      ],
      "metadata": {
        "id": "G1P99hkNj0gd"
      },
      "id": "G1P99hkNj0gd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churning_df= pd.read_csv(churning_data_path)"
      ],
      "metadata": {
        "id": "zOTlWOPij470"
      },
      "id": "zOTlWOPij470",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churning_df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1, inplace= True)"
      ],
      "metadata": {
        "id": "EXpqfIHnj734"
      },
      "id": "EXpqfIHnj734",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churning_df_dummies= pd.get_dummies(churning_df,columns=['Geography', 'Gender'], drop_first= True)"
      ],
      "metadata": {
        "id": "-aCt7VvCj-1G"
      },
      "id": "-aCt7VvCj-1G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churning_df_dummies.info()"
      ],
      "metadata": {
        "id": "z62sDffRkBOm"
      },
      "id": "z62sDffRkBOm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain a tree, first by applying pre-pruning and then by applying post-pruning. Compare the results (i.e., the prediction of both trees on test data).\n",
        "\n",
        "Only obtain the feature importance and plot the tree for one tree (the best one between the two trees)."
      ],
      "metadata": {
        "id": "lqjl3PSCkGnL"
      },
      "id": "lqjl3PSCkGnL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue working independently."
      ],
      "metadata": {
        "id": "OQzn4MpXkkfi"
      },
      "id": "OQzn4MpXkkfi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sc9965Mn93jO"
      },
      "id": "sc9965Mn93jO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUfESMC293gF"
      },
      "id": "AUfESMC293gF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcLcsOGE93YH"
      },
      "id": "EcLcsOGE93YH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UDouBCn593Ut"
      },
      "id": "UDouBCn593Ut",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-IxfEXT93PN"
      },
      "id": "w-IxfEXT93PN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rG0CCkk93NG"
      },
      "id": "8rG0CCkk93NG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}