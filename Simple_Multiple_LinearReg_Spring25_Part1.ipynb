{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1f701cd",
      "metadata": {
        "id": "b1f701cd"
      },
      "source": [
        "## Simple and Multiple Linear Regression with Python\n",
        "\n",
        "__Relevant textbook sections:__\n",
        "\n",
        "Chapter 3: Linear Regression\n",
        "\n",
        "3.1. Simple Linear Regression\n",
        "\n",
        "3.2. Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several options to run a regression analysis in Python. You can use Scikit-learn, Statsmodels, SciPy, and probably other packages.\n",
        "\n",
        "We are going to learn how to do a linear regression analysis using the Scikit-learn package."
      ],
      "metadata": {
        "id": "mQVuUCcgqKF2"
      },
      "id": "mQVuUCcgqKF2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common question among students who are taking this course and just took the Statistic with R course: Why doesn't Scikit-Learn provide p-values?\n",
        "\n",
        "Scikit-learn's LinearRegression is designed for efficient computation and predictive performance, not hypothesis testing or model diagnostics.\n",
        "\n",
        "**Statistical significance is not essential for many machine learning tasks, as the focus is typically on predictive accuracy rather than understanding the underlying relationships between variables.**"
      ],
      "metadata": {
        "id": "KSLP2hKm0GAJ"
      },
      "id": "KSLP2hKm0GAJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f9dbb5",
      "metadata": {
        "id": "68f9dbb5"
      },
      "outputs": [],
      "source": [
        "# Importing some of the required packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2282bd",
      "metadata": {
        "id": "aa2282bd"
      },
      "source": [
        "We are going to use the Boston dataset.\n",
        "\n",
        "I chose to use this dataset to illustrate linear regression in Python because you are already familiar with it (this was the main dataset we used to learn regression in R).\n",
        "\n",
        "__REMINDER !!!__ This is NOT the ethically compromised Boston dataset. It is a different one.\n",
        "\n",
        "<br>\n",
        "\n",
        "1) Download the \"Boston.csv\" from Canvas.\n",
        "\n",
        "2) Upload the \"Boston.csv\" to your Google Drive. I recommend you to create a folder called \"Datasets_CAP4631C\" in your Google Drive to keep all the datasets for this class.\n",
        "\n",
        "3) Mount Google Drive in Colab by running the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kXR_fhC-u3pa"
      },
      "id": "kXR_fhC-u3pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_boston = \"/content/drive/MyDrive/CAP 4631C/Datasets_CAP4631C/Boston.csv\""
      ],
      "metadata": {
        "id": "RARdlEJTvB3F"
      },
      "id": "RARdlEJTvB3F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df = pd.read_csv (path_boston)"
      ],
      "metadata": {
        "id": "w7J2V_QYvMaN"
      },
      "id": "w7J2V_QYvMaN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e04514",
      "metadata": {
        "id": "86e04514"
      },
      "outputs": [],
      "source": [
        "boston_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6010b0e",
      "metadata": {
        "id": "d6010b0e"
      },
      "outputs": [],
      "source": [
        "boston_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to evaluate the quality (performance) of an equation?**\n",
        "\n",
        "**The Stat approach and the ML approach**"
      ],
      "metadata": {
        "id": "tmUymoePDL_p"
      },
      "id": "tmUymoePDL_p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stat approach**\n",
        "\n",
        "Evaluate the performance of the equation only on the training data, but make sure to adjust the evaluation for overfitting.\n",
        "\n",
        "How to adjust for overfitting?\n",
        "\n",
        "Use adjusted R squared, Residuals Standard Error (RSE), Cp, BIC, ... (or any metric that adjusts for overfitting).\n",
        "\n",
        "**ML aproach**\n",
        "\n",
        "Evaluate the performance of the equation on test data by using a single test-training split or cross-validation."
      ],
      "metadata": {
        "id": "chHdudNYeVMW"
      },
      "id": "chHdudNYeVMW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardize the predictors before applying linear regression?**\n",
        "\n",
        "It is not neccesary to do so when applying linear regression (it is not wrong if you do it, it is just not a neccesity). Read ISLP book, page 242 for an explanation.\n",
        "\n",
        "Other regression techniques do require the standardization of the predictors (KNN regression, Ridge Regression, etc).\n",
        "\n",
        "See this Minitab post for more ideas about this issue:\n",
        "\n",
        "https://blog.minitab.com/en/adventures-in-statistics-2/when-is-it-crucial-to-standardize-the-variables-in-a-regression-model\n",
        "\n"
      ],
      "metadata": {
        "id": "GoC3TiTrxzin"
      },
      "id": "GoC3TiTrxzin"
    },
    {
      "cell_type": "markdown",
      "id": "9cb771fb",
      "metadata": {
        "id": "9cb771fb"
      },
      "source": [
        "### Simple Linear Regression: Stat approach\n",
        "\n",
        "Let's do the same example we did in the Statistics with R class. That is, the linear regression of __medv__ versus __lstat__.\n",
        "\n",
        "Before applying regression, let's do the usual preliminary analysis. Specifically, let's compute the __correlation coefficient__ between medv and lstat and do a __scatterplot__ between these two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the many options we have to compute the correlation coefficient in Python is to use the corr() method from the Pandas package."
      ],
      "metadata": {
        "id": "nkM1fc8pdPJZ"
      },
      "id": "nkM1fc8pdPJZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c20e7d6e",
      "metadata": {
        "id": "c20e7d6e"
      },
      "outputs": [],
      "source": [
        "boston_df[['lstat', 'medv']].corr()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you only want to get the correlation value\n",
        "\n",
        "boston_df[['lstat', 'medv']].corr().iloc [0, 1]"
      ],
      "metadata": {
        "id": "1Agn0nI8gslj"
      },
      "id": "1Agn0nI8gslj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "73a96010",
      "metadata": {
        "id": "73a96010"
      },
      "source": [
        "**Scatterplot**\n",
        "\n",
        "Do a scatterplot between lstat and medv using using the functions from the **matplotlib package**.\n",
        "\n",
        "**About matplotlib**: Quoting from **w3schools** ... \"Most of Matplotlib utilities lies under the pyplot submodule\"\n",
        "\n",
        "That's why we import Matplotlib and the pyplot submodule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6017f13",
      "metadata": {
        "id": "a6017f13"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c9ad26",
      "metadata": {
        "id": "e0c9ad26"
      },
      "source": [
        "We are going to use _plt.scatter()_ method since it is the conventional way of doing a scatter plot.\n",
        "\n",
        "Comment: If your aren't trying to do a sophisticated scatter plot, like in our case, you could also use _plt.plot()_ to do a scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1d1079",
      "metadata": {
        "scrolled": true,
        "id": "ff1d1079"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8)) # Play around with different values in this tuple to get different figure sizes\n",
        "\n",
        "plt.scatter(boston_df['lstat'], boston_df['medv'], c='blue')\n",
        "\n",
        "plt.ylabel(\"medv\")\n",
        "\n",
        "plt.xlabel(\"lstat\")\n",
        "\n",
        "plt.title (\"Median house values VS % of houses with low SES in the neighborhood\")\n",
        "\n",
        "# The next line is optional. Use if you want to add more marks on the y axis (plt.xticks for x axis)\n",
        "\n",
        "plt.yticks(np.arange(boston_df['medv'].min(), boston_df['medv'].max()+1, 5))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Obtain the linear regression model**"
      ],
      "metadata": {
        "id": "PqsDsYQHe9r9"
      },
      "id": "PqsDsYQHe9r9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by importing the 'LinearRegression' function from the scikit-learn module 'linear_model'."
      ],
      "metadata": {
        "id": "xdvoVApmhluW"
      },
      "id": "xdvoVApmhluW"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "D7MOg-KBjgGE"
      },
      "id": "D7MOg-KBjgGE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "97f31289",
      "metadata": {
        "id": "97f31289"
      },
      "source": [
        "Any method part of scikit-learn REQUIRES that we use a __two dimensional object__ to store the predictor(s) values.\n",
        "\n",
        "So, what do we do in this case where we only have one predictor? To store the values of one predictor, we only need need a one-dimensional array. Thus, what do we do?\n",
        "\n",
        "We transform the array with the values of the predictor in a two dimensional array where the number of columns equals 1 and the number of rows equals the number of elements in the array.\n",
        "\n",
        "We can use the reshape() method to do that."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(boston_df['lstat'])"
      ],
      "metadata": {
        "id": "gnM_QJmTCztS"
      },
      "id": "gnM_QJmTCztS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'lstat' as a one dimensional array\n",
        "\n",
        "print ( np.array(boston_df['lstat']).ndim )\n",
        "\n",
        "print ( np.array(boston_df['lstat']).shape )\n"
      ],
      "metadata": {
        "id": "YkZOiV_YfIIk"
      },
      "id": "YkZOiV_YfIIk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b92f1cc",
      "metadata": {
        "id": "1b92f1cc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 'lstat' as a two dimensional array with m rows and 1 column\n",
        "\n",
        "np.array(boston_df['lstat']).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01908c57",
      "metadata": {
        "id": "01908c57"
      },
      "outputs": [],
      "source": [
        "np.array(boston_df['lstat']).reshape(-1,1).ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bdc98e1",
      "metadata": {
        "id": "3bdc98e1"
      },
      "outputs": [],
      "source": [
        "np.array(boston_df['lstat']).reshape(-1,1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46306894",
      "metadata": {
        "id": "46306894"
      },
      "source": [
        "Now that we undertand how to transform the predictor into a two dimensional array, we create a variable to store the predictor and another one to store the outcome."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_lstat = np.array(boston_df['lstat']).reshape(-1,1)"
      ],
      "metadata": {
        "id": "BnRDXkjNwYaV"
      },
      "id": "BnRDXkjNwYaV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No need to convert into NumPy or reshape the column with the outcome variable\n",
        "\n",
        "y = boston_df['medv']"
      ],
      "metadata": {
        "id": "TdZtNLL9wsK5"
      },
      "id": "TdZtNLL9wsK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we invoke the fit() method, to fit a linear regression model using the predictor and outcome data."
      ],
      "metadata": {
        "id": "8e3p4s8Bok1J"
      },
      "id": "8e3p4s8Bok1J"
    },
    {
      "cell_type": "code",
      "source": [
        "# I create the 'reg_out_lstat' variable to easily access the regression results\n",
        "\n",
        "reg_out_lstat = LinearRegression().fit(X_lstat, y)"
      ],
      "metadata": {
        "id": "EiCZl3plk0Gl"
      },
      "id": "EiCZl3plk0Gl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e51021f1",
      "metadata": {
        "id": "e51021f1"
      },
      "outputs": [],
      "source": [
        "# Intercept of the regression equation\n",
        "\n",
        "reg_out_lstat.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7a1486",
      "metadata": {
        "id": "ae7a1486"
      },
      "outputs": [],
      "source": [
        "# Slope of the regression equation\n",
        "\n",
        "reg_out_lstat.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501ce0b8",
      "metadata": {
        "id": "501ce0b8"
      },
      "source": [
        "**Evaluate the quality of the simple linear regression equation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R squared**"
      ],
      "metadata": {
        "id": "Wu0NjqqsprhI"
      },
      "id": "Wu0NjqqsprhI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn has a function to compute R squared. Let's import it:"
      ],
      "metadata": {
        "id": "OHL7zSXNsJG2"
      },
      "id": "OHL7zSXNsJG2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3980fbe9",
      "metadata": {
        "id": "3980fbe9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the predictions of y given by the equation in an array.\n",
        "# This is optional but recommmended\n",
        "\n",
        "y_pred_lstat= reg_out_lstat.predict(X_lstat)"
      ],
      "metadata": {
        "id": "I94EpWMhxLcQ"
      },
      "id": "I94EpWMhxLcQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that in scikit-learn, when we use predict(), we need to pass the values of the predictor as an argument."
      ],
      "metadata": {
        "id": "yaT1ezGcCF9X"
      },
      "id": "yaT1ezGcCF9X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d59ced4",
      "metadata": {
        "id": "1d59ced4"
      },
      "outputs": [],
      "source": [
        "r2_score(y, y_pred_lstat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eb475cf",
      "metadata": {
        "id": "9eb475cf"
      },
      "source": [
        "**RSE**\n",
        "\n",
        "Given that scikit learn does not have a function to compute RSE, we will define our own function to compute. Defining a function is NOT mandatory, but it keeps the code cleaner and facilitates re-using the function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a reminder, this is the formula of RSE:\n",
        "\n",
        "sqrt (SSE / (n-p-1) )\n",
        "\n",
        "where,\n",
        "\n",
        "SSE: Sum of Square of Errors\n",
        "\n",
        "n: sample size\n",
        "\n",
        "p: number of predictors"
      ],
      "metadata": {
        "id": "MdEOgp5KsT3L"
      },
      "id": "MdEOgp5KsT3L"
    },
    {
      "cell_type": "code",
      "source": [
        "def rse_calculator (y_actual, y_predicted, p):\n",
        "\n",
        "  rse_value = np.sqrt ( np.sum((y_actual - y_predicted)**2) / (y_actual.size - p -1) )\n",
        "\n",
        "  return np.round (rse_value, 4)"
      ],
      "metadata": {
        "id": "T4QiXBLvs05a"
      },
      "id": "T4QiXBLvs05a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rse_calculator(y, y_pred_lstat, 1)"
      ],
      "metadata": {
        "id": "leeEWHsWs4TD"
      },
      "id": "leeEWHsWs4TD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is RSE low (= good)?"
      ],
      "metadata": {
        "id": "JatMtXDiyD67"
      },
      "id": "JatMtXDiyD67"
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficient of variation\n",
        "# RSE / mean of Y\n",
        "\n",
        "rse_calculator(y, y_pred_lstat, 1) / np.mean (y)"
      ],
      "metadata": {
        "id": "X82IhiY3yI6o"
      },
      "id": "X82IhiY3yI6o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "48d9aa10",
      "metadata": {
        "id": "48d9aa10"
      },
      "source": [
        "__How to make predictions with the estimated equation?__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97bca91c",
      "metadata": {
        "id": "97bca91c"
      },
      "source": [
        "For example, let's predict the values of medv based on the regression equation for five new neighborhoods. These are the values of lstat for these five new neighborhoods:\n",
        "\n",
        "4.5, 5, 7, 8.5, and 9.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98a5792",
      "metadata": {
        "id": "a98a5792"
      },
      "outputs": [],
      "source": [
        "reg_out_lstat.predict( np.array( [4.5, 5, 7, 8.5, 9.3] ).reshape (-1, 1) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c5b695",
      "metadata": {
        "id": "d5c5b695"
      },
      "source": [
        "**Plot of Residuals versus Predicted values**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcfadeb",
      "metadata": {
        "id": "bdcfadeb"
      },
      "source": [
        "First, let's repeat the previous scatter plot of medv VS LSTAT, but let's add the regression line to it this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2d2a51",
      "metadata": {
        "scrolled": true,
        "id": "ea2d2a51"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8)) # Play around with values in this tuple to get different figure sizes\n",
        "\n",
        "plt.scatter(boston_df['lstat'], boston_df['medv'], c='blue')\n",
        "\n",
        "plt.ylabel(\"medv\")\n",
        "\n",
        "plt.xlabel(\"lstat\")\n",
        "\n",
        "plt.title (\"Median house values VS % of houses with low SES in the neighborhood\")\n",
        "\n",
        "plt.yticks(np.arange(boston_df['medv'].min(), boston_df['medv'].max()+1, 5))\n",
        "\n",
        "# This is the additional statement needed to plot the regression line in the scatterplot\n",
        "\n",
        "plt.plot(boston_df['lstat'], y_pred_lstat, c='red', ls='-') # ls means line style. Use '-' to get a solid line. Use '--' for a dashed line\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a78e30",
      "metadata": {
        "id": "74a78e30"
      },
      "outputs": [],
      "source": [
        "# Let's compute the residuals and store them in an array.\n",
        "# residuals = y actual - y predicted\n",
        "\n",
        "residuals_lstat = y - y_pred_lstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26990790",
      "metadata": {
        "id": "26990790"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_pred_lstat, residuals_lstat,c='blue')\n",
        "\n",
        "plt.xlabel(\"Predicted y\") # Predicted values of medv obtained from the equation\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.axhline(0, c='red',ls='--')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357e4a9c",
      "metadata": {
        "id": "357e4a9c"
      },
      "source": [
        "### Multiple Linear Regression: Stat approach\n",
        "\n",
        "We are still using the Boston dataset.\n",
        "\n",
        "As an illustration, let's do the multiple linear regression of medv VS lstat and rm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_lstat_rm= boston_df[['lstat','rm']]\n",
        "\n",
        "# no need to convert to a two dimensional array because boston_df[['lstat','rm']]  is a dataframe (data frame have two dimensions)"
      ],
      "metadata": {
        "id": "ZmjXEN057cv9"
      },
      "id": "ZmjXEN057cv9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I create the 'reg_out_lstat_rm' variable to easily access the regression results\n",
        "\n",
        "reg_out_lstat_rm = LinearRegression().fit(X_lstat_rm, y)"
      ],
      "metadata": {
        "id": "-KhOBgBIvD7u"
      },
      "id": "-KhOBgBIvD7u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1407ff54",
      "metadata": {
        "id": "1407ff54"
      },
      "outputs": [],
      "source": [
        "# Intercept of the regression equation\n",
        "\n",
        "reg_out_lstat_rm.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf898b5",
      "metadata": {
        "id": "5bf898b5"
      },
      "outputs": [],
      "source": [
        "# Coefficients of the multiple regression equation\n",
        "\n",
        "reg_out_lstat_rm.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code cell shows you how to create a data frame with all the coefficients displayed in a nice way:"
      ],
      "metadata": {
        "id": "OdkwERXKOtTT"
      },
      "id": "OdkwERXKOtTT"
    },
    {
      "cell_type": "code",
      "source": [
        "# to retrieve the names of the predictors used in the model\n",
        "\n",
        "reg_out_lstat_rm.feature_names_in_"
      ],
      "metadata": {
        "id": "aPSQxPshMXAE"
      },
      "id": "aPSQxPshMXAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_values = np.concatenate(([reg_out_lstat_rm.intercept_], reg_out_lstat_rm.coef_))\n",
        "# need to convert the intercept value into a list or array bf using it in concatenate.\n",
        "\n",
        "column_names = np.concatenate((['Intercept'], reg_out_lstat_rm.feature_names_in_))\n",
        "\n",
        "# Create a data frame to display the results\n",
        "\n",
        "coefficients_df = pd.DataFrame({'Coefficient Name': column_names, 'Coefficient Value': coef_values})\n",
        "\n",
        "print(coefficients_df)"
      ],
      "metadata": {
        "id": "6eOb709UMhzo"
      },
      "id": "6eOb709UMhzo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7092ed05",
      "metadata": {
        "id": "7092ed05"
      },
      "source": [
        "**Evaluate the quality of a multiple linear regression equation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R squared**"
      ],
      "metadata": {
        "id": "mhXZl5Br9gyp"
      },
      "id": "mhXZl5Br9gyp"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lstat_rm= reg_out_lstat_rm.predict(X_lstat_rm)"
      ],
      "metadata": {
        "id": "k3rnkTAk8cTa"
      },
      "id": "k3rnkTAk8cTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e97b8fd",
      "metadata": {
        "id": "6e97b8fd"
      },
      "outputs": [],
      "source": [
        "r2_score ( y, y_pred_lstat_rm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "440683a2",
      "metadata": {
        "id": "440683a2"
      },
      "source": [
        "**Adjusted R squared**\n",
        "\n",
        "If you want to use a classic statistical approach to compare a multiple linear equation with another one with a different number of predictors, you should adjust for overfitting. Adjusted R squared is one of the many metrics that does that (RSE does it too)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In R, the function used to apply regression gives us both R squared and adjusted R squared. Scikit-learn gives us R squared but not adjusted R squared."
      ],
      "metadata": {
        "id": "P8HnDveOPnMu"
      },
      "id": "P8HnDveOPnMu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute adjusted r squared, we are going t write our own function based on this formula:\n",
        "\n",
        "adj r squared = 1 - (1 -  r squared) * ((n - 1)/(n-p-1))"
      ],
      "metadata": {
        "id": "_nrIyNoQHYhJ"
      },
      "id": "_nrIyNoQHYhJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_r2_calculator (r2_value, n, p):\n",
        "\n",
        "  adj_r2_value = 1 - (1- r2_value) * ( (n - 1) / (n - p - 1) )\n",
        "\n",
        "  return np.round (adj_r2_value, 4)"
      ],
      "metadata": {
        "id": "dLUD8o_WIIhe"
      },
      "id": "dLUD8o_WIIhe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'shape' gives us the sample size (using index 0) and the number of predictors (using index 1)\n",
        "\n",
        "adj_r2_calculator (r2_score ( y, y_pred_lstat_rm), X_lstat_rm.shape[0], X_lstat_rm.shape[1])"
      ],
      "metadata": {
        "id": "sWE_nVetIIWw"
      },
      "id": "sWE_nVetIIWw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RSE**\n",
        "\n",
        "RSE also adjusts for overfitting; thus, it can be used to compare equations with different number of predictors."
      ],
      "metadata": {
        "id": "grs289DP-MQ_"
      },
      "id": "grs289DP-MQ_"
    },
    {
      "cell_type": "code",
      "source": [
        "rse_calculator(y, y_pred_lstat_rm, X_lstat_rm.shape[1])"
      ],
      "metadata": {
        "id": "kiiW7hdFJVCx"
      },
      "id": "kiiW7hdFJVCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to use Adjusted R Squared and RSE to compare equations with different number of predictors?**"
      ],
      "metadata": {
        "id": "QmtKaQLy-h6y"
      },
      "id": "QmtKaQLy-h6y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the equation that only uses 'lstat' as predictor with the one that uses 'lstat' and 'rm'."
      ],
      "metadata": {
        "id": "dFr2fT1gG4Qo"
      },
      "id": "dFr2fT1gG4Qo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Fragments from the R class:__\n",
        "\n",
        "*In this course, unless I tell you otherwise, we will consider that an equation is better than another one only if the **increase in Adjusted R Squared is deemed to be practically significant**. When is an increase in Adjusted R squared practically significant? If it is at least a 5% increase  (**% increase in Adj R squared >= 5%**)*\n",
        "\n",
        "*In some context, people are taught that as long as Adjusted R Squared increases, even if only by a little bit, that should be taken as a sign of improvement. However, such an approach is too naive and simplistic.*"
      ],
      "metadata": {
        "id": "-m8gmavkHuaf"
      },
      "id": "-m8gmavkHuaf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In this course, unless I tell you otherwise, we will consider that an equation is better than  another one only if the **decrease in RSE is deemed to be practically significant**. When is decrease in RSE practically significant? If it is at least a 5% decrease  (**% decrease in RSE >= 5%**).*\n",
        "\n",
        "*In some context, people are taught that as long as RSE decreases, even if only by a little bit, that should be taken as a sign of improvement. However, such an approach is too naive and simplistic.*"
      ],
      "metadata": {
        "id": "Htz1YmGCLTEe"
      },
      "id": "Htz1YmGCLTEe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the % increase in adjusted R squared from model 1 (lstat only) to model 2 (lstat and rm)"
      ],
      "metadata": {
        "id": "xVn9vbY0R8Uc"
      },
      "id": "xVn9vbY0R8Uc"
    },
    {
      "cell_type": "code",
      "source": [
        "adj_r_sq_lstat = adj_r2_calculator (r2_score ( y, y_pred_lstat), X_lstat.shape[0], X_lstat.shape[1])"
      ],
      "metadata": {
        "id": "oHbk8mpUNKk4"
      },
      "id": "oHbk8mpUNKk4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_r_sq_lstat_rm = adj_r2_calculator (r2_score ( y, y_pred_lstat_rm), X_lstat_rm.shape[0], X_lstat_rm.shape[1])"
      ],
      "metadata": {
        "id": "ZKk4SQSVNKhV"
      },
      "id": "ZKk4SQSVNKhV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# % increase in adjusted R squared\n",
        "\n",
        "( (adj_r_sq_lstat_rm -  adj_r_sq_lstat)/ adj_r_sq_lstat )*100"
      ],
      "metadata": {
        "id": "QuCYR0LxM5B9"
      },
      "id": "QuCYR0LxM5B9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what's the conclusion???"
      ],
      "metadata": {
        "id": "IyMri5UKSVIn"
      },
      "id": "IyMri5UKSVIn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the % decrease in RSE from model 1 (lstat only) to model 2 (lstat and rm)"
      ],
      "metadata": {
        "id": "wok6MQPdTyDV"
      },
      "id": "wok6MQPdTyDV"
    },
    {
      "cell_type": "code",
      "source": [
        "rse_lstat = rse_calculator(y, y_pred_lstat, X_lstat.shape[1])"
      ],
      "metadata": {
        "id": "9PnS7fPNNRjk"
      },
      "id": "9PnS7fPNNRjk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rse_lstat_rm = rse_calculator(y, y_pred_lstat_rm, X_lstat_rm.shape[1])"
      ],
      "metadata": {
        "id": "bmcyvM3eNRVg"
      },
      "id": "bmcyvM3eNRVg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "( (rse_lstat_rm - rse_lstat)/rse_lstat ) * 100"
      ],
      "metadata": {
        "id": "_lSEb1QENm1t"
      },
      "id": "_lSEb1QENm1t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion???"
      ],
      "metadata": {
        "id": "aKFBSJI5UYeR"
      },
      "id": "aKFBSJI5UYeR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A second example of Linear Regression with Python: the prostate dataset."
      ],
      "metadata": {
        "id": "mth2mHkmOhAR"
      },
      "id": "mth2mHkmOhAR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the prostate.csv file from Canvas. Read it as a Pandas data frame and call it _prostate_df_\n",
        "\n",
        "Info about this dataset (from the Elements of Statistical Learning):\n",
        "\n",
        "_\"The data for this example come from a study by Stamey et al. (1989). They\n",
        "examined the correlation between the level of prostate-specific antigen (lpsa) and\n",
        "a number of clinical measures in men who were about to receive a radical\n",
        "prostatectomy. The variables are log cancer volume (lcavol), log prostate\n",
        "weight (lweight), age, log of the amount of benign prostatic hyperplasia\n",
        "(lbph), seminal vesicle invasion (svi), log of capsular penetration (lcp),\n",
        "Gleason score (gleason), and percent of Gleason scores 4 or 5 (pgg45).\"_\n",
        "\n",
        "__The outcome variable is _lpsa_.__"
      ],
      "metadata": {
        "id": "R0v_EB6iZAnk"
      },
      "id": "R0v_EB6iZAnk"
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_data_path = \"/content/drive/MyDrive/CAP 4631C/Datasets_CAP4631C/prostate.csv\""
      ],
      "metadata": {
        "id": "O5L3H_6EZQPt"
      },
      "id": "O5L3H_6EZQPt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_df = pd.read_csv(prostate_data_path)"
      ],
      "metadata": {
        "id": "vvgTSp7HZSAu"
      },
      "id": "vvgTSp7HZSAu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_df.info()"
      ],
      "metadata": {
        "id": "GuAB3ZB4ZWMt"
      },
      "id": "GuAB3ZB4ZWMt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the last column. Not useful\n",
        "\n",
        "prostate_df.drop (['train'],axis=1, inplace= True)"
      ],
      "metadata": {
        "id": "bHAGfqTnaaD8"
      },
      "id": "bHAGfqTnaaD8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_df.info()"
      ],
      "metadata": {
        "id": "rGmkYi9EacW5"
      },
      "id": "rGmkYi9EacW5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the best predictor to use in a simple LR model (a model with only one variable)"
      ],
      "metadata": {
        "id": "mJ0M6wt3ai53"
      },
      "id": "mJ0M6wt3ai53"
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_df.corr()"
      ],
      "metadata": {
        "id": "zbXkYEXVau99"
      },
      "id": "zbXkYEXVau99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prostate_df.corr()['lpsa']"
      ],
      "metadata": {
        "id": "hc3UQgEla4mR"
      },
      "id": "hc3UQgEla4mR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the statistical approach and RSE to compare two equations:\n",
        "\n",
        "The equation that only includes the predictor you chose in the previous step.\n",
        "\n",
        "The equation that includes the predictor you chose in the previous step AND 'lcp'."
      ],
      "metadata": {
        "id": "wDhPozKndaJF"
      },
      "id": "wDhPozKndaJF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONTINUE WORKING INDEPENDENTLY FROM HERE ON!"
      ],
      "metadata": {
        "id": "xVK5JFsE03_D"
      },
      "id": "xVK5JFsE03_D"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}